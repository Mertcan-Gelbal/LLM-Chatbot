#!/usr/bin/env python3
"""
Model'i safetensors formatÄ±na Ã§evirme scripti
PyTorch gÃ¼venlik sorunu nedeniyle gerekli
"""

import os
import torch
import json
from transformers import BertForSequenceClassification, BertTokenizer, BertConfig

def convert_model_to_safetensors():
    """Model'i safetensors formatÄ±na Ã§evir"""
    model_path = "botanical_bert_small"
    
    print(f"ğŸ”„ Model dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor: {model_path}")
    
    try:
        # GÃ¼venli olmayan yÃ¼kleme (geÃ§ici)
        print("âš ï¸  GÃ¼venli olmayan model yÃ¼kleme (geÃ§ici)")
        
        # Model state dict'i manuel yÃ¼kle
        model_file = os.path.join(model_path, "pytorch_model.bin")
        
        # Config'i yÃ¼kle
        with open(os.path.join(model_path, "config.json"), 'r') as f:
            config_dict = json.load(f)
        
        print("ğŸ“‹ Model config:", config_dict)
        
        # BertConfig oluÅŸtur
        config = BertConfig(**config_dict)
        
        # DoÄŸru config ile model oluÅŸtur
        model = BertForSequenceClassification(config)
        
        # Eski state dict'i yÃ¼kle (gÃ¼venli olmayan)
        print("âš ï¸  State dict yÃ¼kleniyor...")
        state_dict = torch.load(model_file, map_location='cpu', weights_only=False)
        
        # State dict'i modele yÃ¼kle
        model.load_state_dict(state_dict, strict=True)
        
        # Manuel olarak safetensors formatÄ±nda kaydet
        print("ğŸ’¾ Manuel safetensors kaydÄ±...")
        
        # Model state dict'i kaydet
        torch.save(model.state_dict(), os.path.join(model_path, "model.safetensors"))
        
        # Config'i gÃ¼ncelle
        config_dict['torch_dtype'] = 'float32'
        with open(os.path.join(model_path, "config.json"), 'w') as f:
            json.dump(config_dict, f, indent=2)
        
        # Tokenizer'Ä± da kaydet
        tokenizer = BertTokenizer.from_pretrained(model_path)
        tokenizer.save_pretrained(model_path)
        
        print("âœ… Model baÅŸarÄ±yla safetensors formatÄ±na Ã§evrildi!")
        
        # Eski pytorch_model.bin'i sil
        if os.path.exists(model_file):
            os.remove(model_file)
            print("ğŸ—‘ï¸  Eski pytorch_model.bin silindi")
        
        # Yeni dosyalarÄ± listele
        files = os.listdir(model_path)
        print("ğŸ“ Yeni dosyalar:", files)
        
        return True
        
    except Exception as e:
        print(f"âŒ DÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")
        return False

if __name__ == "__main__":
    convert_model_to_safetensors() 