#!/usr/bin/env python3
"""
Basit TarÄ±msal BERT Fine-tuning
ArkadaÅŸÄ±nÄ±n AG News koduna benzer yapÄ±
"""

import torch
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, f1_score
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from transformers import (
    BertTokenizer, BertForSequenceClassification,
    get_linear_schedule_with_warmup
)
import matplotlib.pyplot as plt
import json
from pathlib import Path

# --- TarÄ±msal veri setini hazÄ±rlayan fonksiyon ---
def load_agricultural_data():
    """TarÄ±msal veri setini yÃ¼kle ve hazÄ±rla"""
    
    # EÄŸer varolan veri seti varsa yÃ¼kle
    data_path = Path("../Data/agricultural_bert_dataset.json")
    if data_path.exists():
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        texts = [item['text'] for item in data]
        labels = [item['label'] for item in data]
        
        # Label mapping
        unique_labels = list(set(labels))
        label_map = {label: i for i, label in enumerate(unique_labels)}
        numeric_labels = [label_map[label] for label in labels]
        
        print(f"Loaded {len(texts)} samples with {len(unique_labels)} categories")
        print(f"Categories: {unique_labels}")
        
    else:
        # Manuel tarÄ±msal veri seti oluÅŸtur
        texts = [
            # Bitki hastalÄ±klarÄ±
            "Elmada erken yanÄ±klÄ±ÄŸÄ± bakteriyel bir hastalÄ±ktÄ±r ve hÄ±zla yayÄ±lÄ±r",
            "Domates yapraklarÄ±nda sarÄ± lekeler beslenme eksikliÄŸinden kaynaklanÄ±r", 
            "BuÄŸday paslanmasÄ± fungal hastalÄ±k olup nem ile artÄ±ÅŸ gÃ¶sterir",
            "Patates mildiyÃ¶sÃ¼ soÄŸuk nemli havalarda gÃ¶rÃ¼lÃ¼r",
            "Armut ateÅŸ yanÄ±klÄ±ÄŸÄ± bakteriyel kÃ¶kenli ciddi hastalÄ±ktÄ±r",
            
            # YetiÅŸtirme teknikleri
            "BuÄŸday ekim zamanÄ± toprak sÄ±caklÄ±ÄŸÄ±na baÄŸlÄ± olarak belirlenir",
            "HavuÃ§ yetiÅŸtirmede derin gevÅŸek toprak tercih edilir",
            "Domates sulama dÃ¼zenli yapÄ±lmalÄ± aÅŸÄ±rÄ± su verilmemeli",
            "MÄ±sÄ±r ekim derinliÄŸi 3-5 cm arasÄ±nda olmalÄ±dÄ±r",
            "Fasulye sÄ±cak iklim seven bir bitkidir",
            
            # GÃ¼breleme
            "Azotlu gÃ¼bre yaprak geliÅŸimini hÄ±zlandÄ±rÄ±r",
            "Fosforlu gÃ¼bre kÃ¶k sistemi geliÅŸimini destekler",
            "Potasyum gÃ¼bre meyve kalitesini artÄ±rÄ±r",
            "Organik gÃ¼bre toprak yapÄ±sÄ±nÄ± iyileÅŸtirir",
            "KireÃ§ asit topraklarÄ± nÃ¶tralize eder",
            
            # Ã‡evre faktÃ¶rleri
            "Toprak pH deÄŸeri 6.0-7.0 arasÄ±nda ideal",
            "AÅŸÄ±rÄ± sÄ±caklÄ±k bitki stresine neden olur",
            "Don bitkiler iÃ§in ciddi tehlike oluÅŸturur",
            "RÃ¼zgar tuz taÅŸÄ±nÄ±mÄ±nÄ± etkiler",
            "Nem hastalÄ±k geliÅŸimini etkiler"
        ]
        
        labels = [
            # Bitki hastalÄ±klarÄ±
            "plant_disease", "plant_disease", "plant_disease", "plant_disease", "plant_disease",
            # YetiÅŸtirme teknikleri  
            "crop_management", "crop_management", "crop_management", "crop_management", "crop_management",
            # GÃ¼breleme
            "crop_management", "crop_management", "crop_management", "crop_management", "crop_management",
            # Ã‡evre faktÃ¶rleri
            "environmental_factors", "environmental_factors", "environmental_factors", "environmental_factors", "environmental_factors"
        ]
        
        # Label mapping
        unique_labels = list(set(labels))
        label_map = {label: i for i, label in enumerate(unique_labels)}
        numeric_labels = [label_map[label] for label in labels]
        
        print(f"Created {len(texts)} samples with {len(unique_labels)} categories")
        print(f"Categories: {unique_labels}")
    
    # Train/val/test split
    train_texts, temp_texts, train_labels, temp_labels = train_test_split(
        texts, numeric_labels, test_size=0.4, stratify=numeric_labels, random_state=42)
    
    val_texts, test_texts, val_labels, test_labels = train_test_split(
        temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)
    
    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels, len(unique_labels)

# --- Dataset sÄ±nÄ±fÄ± ---
class AgriculturalDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors='pt'
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(self.labels[idx], dtype=torch.long)
        }

# --- EÄŸitim fonksiyonu ---
def train(model, data_loader, optimizer, scheduler, device):
    model.train()
    total_loss = 0
    for batch in data_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        model.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()
        total_loss += loss.item()
    return total_loss / len(data_loader)

# --- DeÄŸerlendirme fonksiyonu ---
def evaluate(model, data_loader, device):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            preds = torch.argmax(outputs.logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    acc = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
    return acc, precision, f1

# --- Test fonksiyonu ---
def test_model(model, tokenizer, device, num_labels):
    """EÄŸitilmiÅŸ modeli test et"""
    model.eval()
    
    test_questions = [
        "Elmada erken yanÄ±klÄ±ÄŸÄ± nasÄ±l tedavi edilir?",
        "BuÄŸday ekim zamanÄ± ne zaman?", 
        "Toprak pH deÄŸeri neden Ã¶nemli?",
        "Azotlu gÃ¼bre ne iÅŸe yarar?"
    ]
    
    categories = ["plant_disease", "crop_management", "environmental_factors"]
    
    print("\nğŸ§ª Model Test SonuÃ§larÄ±:")
    print("-" * 50)
    
    for question in test_questions:
        # Tokenize
        encoding = tokenizer(
            question,
            truncation=True,
            padding='max_length', 
            max_length=128,
            return_tensors='pt'
        )
        
        input_ids = encoding['input_ids'].to(device)
        attention_mask = encoding['attention_mask'].to(device)
        
        with torch.no_grad():
            outputs = model(input_ids, attention_mask=attention_mask)
            probs = torch.softmax(outputs.logits, dim=1)
            pred_id = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_id].item()
        
        pred_category = categories[pred_id] if pred_id < len(categories) else f"Category_{pred_id}"
        
        print(f"Soru: {question}")
        print(f"Tahmin: {pred_category} (GÃ¼ven: {confidence:.3f})")
        print()

# --- Ana deney fonksiyonu ---
def run_agricultural_experiment():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'ğŸš€ Using device: {device}')

    # Veriyi yÃ¼kle
    train_texts, val_texts, test_texts, train_labels, val_labels, test_labels, num_labels = load_agricultural_data()

    # BERT modelleri
    models_info = {
        'bert-base-uncased': (BertTokenizer, BertForSequenceClassification),
    }

    results = []
    num_epochs = 3
    batch_size = 8  # Jetson iÃ§in kÃ¼Ã§Ã¼k batch

    for model_name, (TokenizerClass, ModelClass) in models_info.items():
        print(f"\nğŸ§  Training {model_name} on Agricultural Data")

        # Model ve tokenizer yÃ¼kle
        tokenizer = TokenizerClass.from_pretrained(model_name)
        model = ModelClass.from_pretrained(model_name, num_labels=num_labels)
        model.to(device)

        # Dataset oluÅŸtur
        train_dataset = AgriculturalDataset(train_texts, train_labels, tokenizer)
        val_dataset = AgriculturalDataset(val_texts, val_labels, tokenizer)
        test_dataset = AgriculturalDataset(test_texts, test_labels, tokenizer)

        # DataLoader oluÅŸtur
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size)
        test_loader = DataLoader(test_dataset, batch_size=batch_size)

        # Optimizer ve scheduler
        optimizer = AdamW(model.parameters(), lr=2e-5)
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=0,
            num_training_steps=len(train_loader) * num_epochs
        )

        # EÄŸitim dÃ¶ngÃ¼sÃ¼
        print("ğŸ“š Training started...")
        for epoch in range(num_epochs):
            loss = train(model, train_loader, optimizer, scheduler, device)
            val_acc, val_prec, val_f1 = evaluate(model, val_loader, device)
            print(f"Epoch {epoch+1}/{num_epochs}: loss={loss:.4f} | val_acc={val_acc:.4f} | val_f1={val_f1:.4f}")

        # Test deÄŸerlendirmesi
        test_acc, test_prec, test_f1 = evaluate(model, test_loader, device)
        results.append({
            'Model': model_name,
            'Accuracy': test_acc,
            'Precision': test_prec,
            'F1-Score': test_f1
        })

        print(f"âœ… {model_name} Test Results:")
        print(f"   Accuracy: {test_acc:.4f}")
        print(f"   Precision: {test_prec:.4f}")
        print(f"   F1-Score: {test_f1:.4f}")

        # Model test et
        test_model(model, tokenizer, device, num_labels)

        # Modeli kaydet
        model_save_path = Path(f"agricultural_{model_name.replace('-', '_')}")
        model_save_path.mkdir(exist_ok=True)
        
        # Basit kaydetme (eski PyTorch iÃ§in)
        try:
            # Config ve tokenizer kaydet
            model.config.save_pretrained(model_save_path)
            tokenizer.save_pretrained(model_save_path)
            
            # Model state dict kaydet
            torch.save(model.state_dict(), model_save_path / "pytorch_model.bin")
            
            print(f"ğŸ’¾ Model saved to {model_save_path}")
        except Exception as e:
            print(f"âŒ Model kaydetme hatasÄ±: {e}")

        # Bellek temizle
        del model
        torch.cuda.empty_cache()

    # SonuÃ§larÄ± gÃ¶ster
    result_df = pd.DataFrame(results)
    print("\nğŸ“Š Final Results on Agricultural Test Set:")
    print(result_df)

    # Grafik Ã§iz
    if len(results) > 0:
        result_df.set_index("Model")[["Accuracy", "Precision", "F1-Score"]].plot.bar(rot=45, figsize=(10,6))
        plt.title("BERT Model Performance on Agricultural Dataset")
        plt.ylabel("Score")
        plt.ylim(0, 1)
        plt.grid(axis="y")
        plt.tight_layout()
        plt.savefig("agricultural_bert_results.png")
        plt.show()
        print("ğŸ“ˆ Grafik agricultural_bert_results.png olarak kaydedildi")

if __name__ == '__main__':
    print("ğŸŒ¾ TarÄ±msal BERT Fine-tuning BaÅŸlatÄ±lÄ±yor...")
    run_agricultural_experiment()
    print("ğŸ‰ EÄŸitim tamamlandÄ±!") 