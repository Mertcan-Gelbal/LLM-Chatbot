#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒ± Agricultural LLM Chatbot System
AI-powered agricultural expert chatbot with RAG capabilities

Features:
- BERT-based text classification
- Knowledge retrieval from agricultural database
- Generative responses with context
- Multi-language support (Turkish/English)
- Interactive web interface

Author: Botanical BERT Team
Version: 1.0.0
"""

import os
import sys
import json
import logging
import warnings
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
from pathlib import Path

import torch
import pandas as pd
import numpy as np
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    pipeline, set_seed
)
from sentence_transformers import SentenceTransformer
import faiss
import gradio as gr

# Suppress warnings
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set seeds for reproducibility
set_seed(42)
torch.manual_seed(42)
np.random.seed(42)

class AgriculturalKnowledgeBase:
    """Agricultural knowledge base with semantic search capabilities"""
    
    def __init__(self, data_path: str = "../Data"):
        self.data_path = Path(data_path)
        self.embeddings_model = None
        self.knowledge_index = None
        self.documents = []
        self.metadata = []
        
    def load_knowledge_base(self) -> bool:
        """Load and index agricultural knowledge"""
        try:
            # Load embedding model
            logger.info("Loading sentence transformer model...")
            self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            # Load agricultural documents
            logger.info("Loading agricultural knowledge base...")
            self._load_agricultural_documents()
            
            # Create vector index
            logger.info("Creating vector index...")
            self._create_vector_index()
            
            logger.info(f"Knowledge base loaded: {len(self.documents)} documents indexed")
            return True
            
        except Exception as e:
            logger.error(f"Error loading knowledge base: {e}")
            return False
    
    def _load_agricultural_documents(self):
        """Load documents from various sources"""
        documents = []
        metadata = []
        
        # Load from detailed CSV
        csv_path = self.data_path / "agricultural_bert_detailed.csv"
        if csv_path.exists():
            df = pd.read_csv(csv_path)
            for _, row in df.iterrows():
                documents.append(row['text'])
                metadata.append({
                    'source': 'agricultural_dataset',
                    'category': row.get('label', 'unknown'),
                    'confidence': 1.0
                })
        
        # Load from JSON dataset
        json_path = self.data_path / "agricultural_bert_dataset.json"
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and 'text' in item:
                            documents.append(item['text'])
                            metadata.append({
                                'source': 'json_dataset',
                                'category': item.get('label', 'unknown'),
                                'confidence': 1.0
                            })
        
        # Add expert knowledge (hardcoded examples)
        expert_knowledge = self._get_expert_knowledge()
        documents.extend(expert_knowledge['texts'])
        metadata.extend(expert_knowledge['metadata'])
        
        self.documents = documents
        self.metadata = metadata
        
    def _get_expert_knowledge(self) -> Dict:
        """Get expert agricultural knowledge"""
        expert_texts = [
            # Bitki HastalÄ±klarÄ±
            "Domates yaprak yanÄ±klÄ±ÄŸÄ± fungal bir hastalÄ±ktÄ±r. Alternaria solani mantarÄ± tarafÄ±ndan neden olur. Yapraklarda kahverengi lekeler gÃ¶rÃ¼lÃ¼r. Nemli ve sÄ±cak havalarda hÄ±zla yayÄ±lÄ±r. BakÄ±r iÃ§erikli fungisitlerle tedavi edilebilir.",
            
            "BuÄŸday pasÄ± hastalÄ±ÄŸÄ± Puccinia tritici mantarÄ± tarafÄ±ndan neden olur. Yapraklarda kÄ±rmÄ±zÄ±msÄ± kahverengi pustÃ¼ller oluÅŸur. RÃ¼zgar ile yayÄ±lÄ±r. DayanÄ±klÄ± Ã§eÅŸit kullanÄ±mÄ± ve fungisit uygulamasÄ± etkilidir.",
            
            "Patates yanÄ±klÄ±ÄŸÄ± Phytophthora infestans mantarÄ± tarafÄ±ndan neden olur. Yapraklarda koyu lekeler, gÃ¶vdede Ã§Ã¼rÃ¼meler gÃ¶rÃ¼lÃ¼r. Nemli havalarda hÄ±zla yayÄ±lÄ±r. Ã–nleyici fungisit uygulamasÄ± ÅŸarttÄ±r.",
            
            # Mahsul YÃ¶netimi
            "BuÄŸday ekimi iÃ§in ideal toprak pH'Ä± 6.0-7.5 arasÄ±ndadÄ±r. Ekim derinliÄŸi 2-3 cm olmalÄ±dÄ±r. Hektara 120-150 kg tohum kullanÄ±lÄ±r. Azotlu gÃ¼bre 3 dÃ¶nemde verilmelidir.",
            
            "Domates fidesi dikimi iÃ§in toprak sÄ±caklÄ±ÄŸÄ± en az 15Â°C olmalÄ±dÄ±r. Fide dikim mesafesi 40x60 cm'dir. Su gereksinimi gÃ¼nde 4-6 litredir. Azot, fosfor, potasyum gÃ¼brelemesi Ã¶nemlidir.",
            
            "MÄ±sÄ±r ekimi iÃ§in toprak sÄ±caklÄ±ÄŸÄ± 12Â°C Ã¼zerinde olmalÄ±dÄ±r. Ekim derinliÄŸi 3-5 cm'dir. SÄ±ra arasÄ± 70 cm, sÄ±ra Ã¼zeri 15-20 cm olmalÄ±dÄ±r. Su gereksinimi yÃ¼ksektir.",
            
            # Ã‡evre FaktÃ¶rleri
            "KuraklÄ±k stresi bitkilerde stomatal kapanmaya neden olur. Yaprak su potansiyeli dÃ¼ÅŸer. Fotosentez hÄ±zÄ± azalÄ±r. Erken uyarÄ± sistemleri kullanÄ±lmalÄ±dÄ±r. Damla sulama sistemi etkilidir.",
            
            "Tuz stresi toprak EC deÄŸerinin 4 dS/m Ã¼zerine Ã§Ä±kmasÄ±yla baÅŸlar. Bitki geliÅŸimi durur. Yaprak kenarlarÄ±nda yanÄ±klar gÃ¶rÃ¼lÃ¼r. Drenaj ve yÄ±kama sulamasÄ± gereklidir.",
            
            # TarÄ±m Teknolojisi
            "AkÄ±llÄ± sulama sistemleri toprak nem sensÃ¶rleri kullanÄ±r. Real-time veri toplar. Su tasarrufu %30-50 arasÄ± saÄŸlar. IoT teknolojisi ile uzaktan kontrol edilebilir.",
            
            "Drone teknolojisi tarÄ±mda harita Ã§Ä±karma, ilaÃ§lama, monitÃ¶ring iÃ§in kullanÄ±lÄ±r. Multispektral kameralar ile bitki saÄŸlÄ±ÄŸÄ± analiz edilir. GPS destekli otomatik uÃ§uÅŸ saÄŸlar."
        ]
        
        expert_metadata = []
        categories = [
            "plant_disease", "plant_disease", "plant_disease",
            "crop_management", "crop_management", "crop_management", 
            "environmental_factors", "environmental_factors",
            "technology", "technology"
        ]
        
        for i, category in enumerate(categories):
            expert_metadata.append({
                'source': 'expert_knowledge',
                'category': category,
                'confidence': 0.95
            })
        
        return {
            'texts': expert_texts,
            'metadata': expert_metadata
        }
    
    def _create_vector_index(self):
        """Create FAISS vector index"""
        if not self.documents:
            raise ValueError("No documents to index")
        
        # Generate embeddings
        embeddings = self.embeddings_model.encode(self.documents, show_progress_bar=True)
        
        # Create FAISS index
        dimension = embeddings.shape[1]
        self.knowledge_index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity
        
        # Normalize embeddings for cosine similarity
        faiss.normalize_L2(embeddings)
        self.knowledge_index.add(embeddings.astype('float32'))
        
    def search_knowledge(self, query: str, top_k: int = 5) -> List[Dict]:
        """Search knowledge base for relevant information"""
        if not self.knowledge_index or not self.embeddings_model:
            return []
        
        try:
            # Generate query embedding
            query_embedding = self.embeddings_model.encode([query])
            faiss.normalize_L2(query_embedding)
            
            # Search
            scores, indices = self.knowledge_index.search(query_embedding.astype('float32'), top_k)
            
            # Prepare results
            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(self.documents):
                    results.append({
                        'text': self.documents[idx],
                        'score': float(score),
                        'metadata': self.metadata[idx]
                    })
            
            return results
            
        except Exception as e:
            logger.error(f"Error searching knowledge base: {e}")
            return []

class AgriculturalClassifier:
    """BERT-based agricultural text classifier"""
    
    def __init__(self, model_path: str = "../Model/botanical_bert_small"):
        self.model_path = Path(model_path)
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        
        # Category mappings
        self.id2label = {
            0: "plant_disease",
            1: "crop_management", 
            2: "plant_genetics",
            3: "environmental_factors",
            4: "food_security",
            5: "technology"
        }
        
        self.label2turkish = {
            "plant_disease": "Bitki HastalÄ±klarÄ±",
            "crop_management": "Mahsul YÃ¶netimi",
            "plant_genetics": "Bitki GenetiÄŸi", 
            "environmental_factors": "Ã‡evre FaktÃ¶rleri",
            "food_security": "GÄ±da GÃ¼venliÄŸi",
            "technology": "TarÄ±m Teknolojisi"
        }
        
    def load_model(self) -> bool:
        """Load BERT classification model"""
        try:
            logger.info(f"Loading BERT model from {self.model_path}")
            
            # Load tokenizer and model
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
            
            # Create pipeline
            self.pipeline = pipeline(
                "text-classification",
                model=self.model,
                tokenizer=self.tokenizer,
                device=0 if torch.cuda.is_available() else -1
            )
            
            logger.info("BERT model loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Error loading BERT model: {e}")
            return False
    
    def classify_text(self, text: str) -> Dict:
        """Classify agricultural text"""
        if not self.pipeline:
            return {"error": "Model not loaded"}
        
        try:
            # Get prediction
            result = self.pipeline(text)[0]
            
            # Parse result
            label = result['label'].replace('LABEL_', '')
            category = self.id2label.get(int(label), "unknown")
            confidence = result['score']
            
            return {
                'category': category,
                'category_turkish': self.label2turkish.get(category, category),
                'confidence': confidence,
                'raw_prediction': result
            }
            
        except Exception as e:
            logger.error(f"Error classifying text: {e}")
            return {"error": str(e)}

class AgriculturalLLMChatbot:
    """Main chatbot class combining classification and knowledge retrieval"""
    
    def __init__(self):
        self.classifier = AgriculturalClassifier()
        self.knowledge_base = AgriculturalKnowledgeBase()
        self.conversation_history = []
        
    def initialize(self) -> bool:
        """Initialize all components"""
        logger.info("Initializing Agricultural LLM Chatbot...")
        
        # Load classifier
        if not self.classifier.load_model():
            logger.error("Failed to load classifier")
            return False
        
        # Load knowledge base  
        if not self.knowledge_base.load_knowledge_base():
            logger.error("Failed to load knowledge base")
            return False
            
        logger.info("Chatbot initialized successfully!")
        return True
    
    def process_query(self, user_input: str, use_history: bool = True) -> Dict:
        """Process user query and generate response"""
        try:
            # Classify query
            classification = self.classifier.classify_text(user_input)
            
            # Search knowledge base
            knowledge_results = self.knowledge_base.search_knowledge(user_input, top_k=3)
            
            # Generate contextual response
            response = self._generate_response(user_input, classification, knowledge_results)
            
            # Update conversation history
            if use_history:
                self.conversation_history.append({
                    'timestamp': datetime.now().isoformat(),
                    'user_input': user_input,
                    'classification': classification,
                    'response': response
                })
            
            return {
                'response': response,
                'classification': classification,
                'knowledge_sources': knowledge_results,
                'conversation_id': len(self.conversation_history)
            }
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                'response': f"ÃœzgÃ¼nÃ¼m, sorgunuzu iÅŸlerken bir hata oluÅŸtu: {str(e)}",
                'error': str(e)
            }
    
    def _generate_response(self, query: str, classification: Dict, knowledge: List[Dict]) -> str:
        """Generate contextual response based on classification and knowledge"""
        
        # Get category info
        category = classification.get('category', 'unknown')
        category_tr = classification.get('category_turkish', 'Bilinmeyen')
        confidence = classification.get('confidence', 0.0)
        
        # Start building response
        response_parts = []
        
        # Add classification info if confidence is high
        if confidence > 0.7:
            response_parts.append(f"ğŸ” **Konu Kategorisi:** {category_tr} (%{confidence*100:.1f} gÃ¼ven)")
        
        # Add relevant knowledge
        if knowledge:
            response_parts.append("\nğŸ“š **Ä°lgili Bilgiler:**")
            
            for i, item in enumerate(knowledge[:2], 1):  # Top 2 results
                score = item['score']
                if score > 0.3:  # Only include relevant results
                    text = item['text'][:300] + "..." if len(item['text']) > 300 else item['text']
                    response_parts.append(f"\n{i}. {text}")
        
        # Add category-specific guidance
        guidance = self._get_category_guidance(category, query)
        if guidance:
            response_parts.append(f"\nğŸ’¡ **Ã–neri:** {guidance}")
        
        # Add follow-up questions
        follow_up = self._get_follow_up_questions(category)
        if follow_up:
            response_parts.append(f"\nâ“ **Devam eden sorular:** {follow_up}")
        
        # Combine response
        if response_parts:
            return "\n".join(response_parts)
        else:
            return self._get_fallback_response(query)
    
    def _get_category_guidance(self, category: str, query: str) -> str:
        """Get category-specific guidance"""
        guidance_map = {
            "plant_disease": "HastalÄ±k teÅŸhisi iÃ§in bitki tÃ¼rÃ¼, belirtiler ve Ã§evre koÅŸullarÄ± Ã¶nemlidir. Uzman desteÄŸi alÄ±nmasÄ± Ã¶nerilir.",
            "crop_management": "Ekim, gÃ¼breleme ve sulama zamanlamasÄ± bÃ¶lgesel koÅŸullara gÃ¶re deÄŸiÅŸebilir. Toprak analizi yaptÄ±rÄ±n.",
            "plant_genetics": "Genetik Ã§eÅŸitlilik ve Ä±slah Ã§alÄ±ÅŸmalarÄ± uzun vadeli projelerdir. Uzman gÃ¶rÃ¼ÅŸÃ¼ alÄ±n.",
            "environmental_factors": "Ã‡evresel stres faktÃ¶rleri erken mÃ¼dahale ile minimize edilebilir. MonitÃ¶ring sistemleri kurun.",
            "food_security": "GÄ±da gÃ¼venliÄŸi kÃ¼resel bir konudur. SÃ¼rdÃ¼rÃ¼lebilir Ã¼retim yÃ¶ntemleri benimseyin.",
            "technology": "TarÄ±m teknolojileri yatÄ±rÄ±m gerektirir. Maliyet-fayda analizi yapÄ±n."
        }
        return guidance_map.get(category, "DetaylÄ± bilgi iÃ§in uzman desteÄŸi alabilirsiniz.")
    
    def _get_follow_up_questions(self, category: str) -> str:
        """Get follow-up questions for each category"""
        questions_map = {
            "plant_disease": "Hangi bitki tÃ¼rÃ¼? Belirtiler ne kadar sÃ¼redir mevcut? Ä°klim koÅŸullarÄ± nasÄ±l?",
            "crop_management": "Toprak tipi nedir? Sulama imkanlarÄ± nasÄ±l? Hangi bÃ¶lgedesiniz?",
            "plant_genetics": "Hangi Ã¶zellikler hedefleniyor? Mevcut Ã§eÅŸitler nelerdir?",
            "environmental_factors": "Hangi stres faktÃ¶rleri gÃ¶zlemlendi? Ã–lÃ§Ã¼m deÄŸerleri nedir?",
            "food_security": "Hangi Ã¼rÃ¼nler iÃ§in planlama yapÄ±lÄ±yor? Hedef pazar nedir?",
            "technology": "BÃ¼tÃ§e ne kadar? Mevcut altyapÄ± durumu nasÄ±l?"
        }
        return questions_map.get(category, "Daha spesifik sorularla devam edebiliriz.")
    
    def _get_fallback_response(self, query: str) -> str:
        """Generate fallback response when no good match found"""
        return f"""
ğŸ¤– **TarÄ±msal AI AsistanÄ±**

Sorununuz iÃ§in spesifik bir bilgi bulamadÄ±m, ancak size yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸacaÄŸÄ±m.

ğŸ“‹ **Ana kategorilerimiz:**
- ğŸ¦  Bitki HastalÄ±klarÄ±
- ğŸŒ¾ Mahsul YÃ¶netimi  
- ğŸ§¬ Bitki GenetiÄŸi
- ğŸŒ¡ï¸ Ã‡evre FaktÃ¶rleri
- ğŸ½ï¸ GÄ±da GÃ¼venliÄŸi
- ğŸš TarÄ±m Teknolojisi

ğŸ’¬ **Ã–rnek sorular:**
- "Domates yaprak yanÄ±klÄ±ÄŸÄ± nedir?"
- "BuÄŸday ekimi nasÄ±l yapÄ±lÄ±r?"
- "AkÄ±llÄ± sulama sistemi nedir?"

LÃ¼tfen daha spesifik bir soru sormayÄ± deneyin!
        """
    
    def get_conversation_history(self) -> List[Dict]:
        """Get conversation history"""
        return self.conversation_history
    
    def clear_history(self):
        """Clear conversation history"""
        self.conversation_history = []

def create_gradio_interface(chatbot: AgriculturalLLMChatbot):
    """Create Gradio web interface"""
    
    def chat_fn(message, history):
        """Gradio chat function"""
        try:
            result = chatbot.process_query(message)
            response = result['response']
            
            # Add classification info to response if available
            classification = result.get('classification', {})
            if 'category_turkish' in classification:
                category = classification['category_turkish']
                confidence = classification.get('confidence', 0)
                response = f"**[{category} - %{confidence*100:.1f}]**\n\n{response}"
            
            return response
            
        except Exception as e:
            return f"Hata: {str(e)}"
    
    # Create interface
    demo = gr.ChatInterface(
        chat_fn,
        title="ğŸŒ± TarÄ±msal AI Chatbot",
        description="""
        **GeliÅŸmiÅŸ TarÄ±msal AI AsistanÄ±**
        
        Bu chatbot aÅŸaÄŸÄ±daki konularda uzmanlaÅŸmÄ±ÅŸtÄ±r:
        - ğŸ¦  Bitki HastalÄ±klarÄ± ve Tedavileri
        - ğŸŒ¾ Mahsul YÃ¶netimi ve Ekim Teknikleri
        - ğŸ§¬ Bitki GenetiÄŸi ve Islah
        - ğŸŒ¡ï¸ Ã‡evresel FaktÃ¶rler ve Stres
        - ğŸ½ï¸ GÄ±da GÃ¼venliÄŸi
        - ğŸš TarÄ±m Teknolojileri
        
        **Ã–rnek sorular:**
        - "Domates yaprak yanÄ±klÄ±ÄŸÄ± belirtileri nelerdir?"
        - "BuÄŸday ekimi iÃ§in hangi toprak Ã¶zellikleri gerekli?"
        - "AkÄ±llÄ± sulama sistemleri nasÄ±l Ã§alÄ±ÅŸÄ±r?"
        """,
        examples=[
            "Domates yaprak yanÄ±klÄ±ÄŸÄ± nedir?",
            "BuÄŸday ekimi nasÄ±l yapÄ±lÄ±r?",
            "Organik gÃ¼bre Ã§eÅŸitleri nelerdir?",
            "AkÄ±llÄ± sulama sistemi avantajlarÄ±",
            "KuraklÄ±k stresi nasÄ±l Ã¶nlenir?",
            "GMO bitkilerin faydalarÄ± nelerdir?"
        ],
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1000px !important;
        }
        .message {
            font-size: 16px !important;
        }
        """,
        retry_btn="ğŸ”„ Tekrar Dene",
        undo_btn="â†©ï¸ Geri Al", 
        clear_btn="ğŸ—‘ï¸ Temizle"
    )
    
    return demo

def main():
    """Main function"""
    print("ğŸŒ± Agricultural LLM Chatbot System Starting...")
    
    # Initialize chatbot
    chatbot = AgriculturalLLMChatbot()
    
    if not chatbot.initialize():
        print("âŒ Failed to initialize chatbot")
        sys.exit(1)
    
    print("âœ… Chatbot initialized successfully!")
    
    # Check if running in interactive mode
    if len(sys.argv) > 1 and sys.argv[1] == "--cli":
        # CLI mode
        print("\nğŸ¤– CLI Chat Mode - Type 'quit' to exit")
        print("=" * 50)
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ You: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q', 'Ã§Ä±kÄ±ÅŸ']:
                    print("ğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                    break
                
                if not user_input:
                    continue
                
                print("ğŸ¤– Processing...")
                result = chatbot.process_query(user_input)
                print(f"\nğŸŒ± Bot: {result['response']}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break
            except Exception as e:
                print(f"âŒ Error: {e}")
    
    else:
        # Web interface mode
        print("ğŸŒ Starting web interface...")
        demo = create_gradio_interface(chatbot)
        
        # Launch
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=True,
            show_error=True
        )

if __name__ == "__main__":
    main() 