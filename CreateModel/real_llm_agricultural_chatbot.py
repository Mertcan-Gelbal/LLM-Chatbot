#!/usr/bin/env python3
"""
GerÃ§ek LLM TarÄ±msal Chatbot
EÄŸitilmiÅŸ GPT-2 model ile doÄŸal dilde cevap Ã¼retimi
"""

import os
import json
import torch
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from transformers import (
    GPT2LMHeadModel, GPT2Tokenizer,
    pipeline
)
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Prompt
from rich.text import Text
from rich import print as rprint

console = Console()

class RealLLMAgriculturalChatbot:
    """GerÃ§ek LLM ile TarÄ±msal Chatbot"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = Path("agricultural_gpt2")
        
        # LLM Pipeline
        self.generator = None
        self.tokenizer = None
        
        # KonuÅŸma hafÄ±zasÄ±
        self.conversation_history = []
        self.session_start = datetime.now()
        
        # Bot kiÅŸiliÄŸi
        self.bot_personality = {
            'name': 'TarÄ±m LLM AI',
            'style': 'Uzman, samimi, yardÄ±msever',
            'expertise': 'GerÃ§ek LLM tabanlÄ± tarÄ±msal danÄ±ÅŸmanlÄ±k'
        }
        
        console.print("ğŸ§  GerÃ§ek LLM TarÄ±msal AI yÃ¼kleniyor...", style="bold green")
        self.initialize_llm()
        self._welcome_user()
    
    def initialize_llm(self):
        """LLM'i baÅŸlat"""
        try:
            if not self.model_path.exists():
                console.print("âŒ EÄŸitilmiÅŸ model bulunamadÄ±! Ã–nce train_agricultural_llm.py Ã§alÄ±ÅŸtÄ±rÄ±n.", style="bold red")
                console.print("ğŸ“– GeÃ§ici olarak GPT-2 base model kullanÄ±lacak...", style="yellow")
                self.model_path = "gpt2"
            
            console.print("ğŸš€ LLM yÃ¼kleniyor...", style="cyan")
            
            # Text generation pipeline
            self.generator = pipeline(
                "text-generation",
                model=str(self.model_path),
                device=0 if torch.cuda.is_available() else -1,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
            )
            
            # Tokenizer
            self.tokenizer = GPT2Tokenizer.from_pretrained(str(self.model_path))
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            console.print("âœ… LLM hazÄ±r!", style="bold green")
            
        except Exception as e:
            console.print(f"âŒ LLM yÃ¼kleme hatasÄ±: {e}", style="bold red")
            raise
    
    def _welcome_user(self):
        """KullanÄ±cÄ±yÄ± karÅŸÄ±la"""
        welcome_panel = Panel.fit(
            "ğŸ§  **GerÃ§ek LLM TarÄ±msal AI'ya HoÅŸ Geldin!**\n\n"
            "ğŸŒŸ **Yeni Teknoloji:**\n"
            "ğŸ¤– **GerÃ§ek Language Model**: GPT-2 tabanlÄ± tarÄ±msal uzman\n"
            "ğŸ’¬ **DoÄŸal Dil**: Ä°nsan gibi akÄ±cÄ± konuÅŸma\n"
            "ğŸ¯ **Ã–zel EÄŸitim**: TarÄ±msal verilerle fine-tuned\n"
            "ğŸ§  **AkÄ±llÄ± Ãœretim**: Template deÄŸil, gerÃ§ek text generation\n"
            "ğŸ“š **UzmanlÄ±k**: HastalÄ±k, yetiÅŸtirme, bakÄ±m konularÄ±nda\n\n"
            "ğŸ’¡ **ArtÄ±k gerÃ§ek bir AI uzmanÄ±yla konuÅŸuyorsunuz!**\n"
            "ğŸ—¨ï¸ Sorunuzu doÄŸal dilde sorun, size detaylÄ± aÃ§Ä±klama yapayÄ±m! ğŸŒ±",
            title="ğŸ§  GerÃ§ek LLM TarÄ±m AI",
            style="bold green"
        )
        console.print(welcome_panel)
    
    def generate_response(self, user_query: str) -> str:
        """LLM ile cevap Ã¼ret"""
        try:
            # Prompt hazÄ±rla
            if self.model_path.name == "agricultural_gpt2":
                # EÄŸitilmiÅŸ model iÃ§in Ã¶zel format
                prompt = f"<|soru|>{user_query}<|cevap|>"
            else:
                # Base GPT-2 iÃ§in genel prompt
                prompt = f"TarÄ±m uzmanÄ± olarak ÅŸu soruyu yanÄ±tlayÄ±n: {user_query}\n\nYanÄ±t:"
            
            # Cevap Ã¼ret
            response = self.generator(
                prompt,
                max_length=min(len(prompt.split()) + 150, 400),  # Adaptive length
                num_return_sequences=1,
                temperature=0.7,
                do_sample=True,
                top_p=0.9,
                repetition_penalty=1.1,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )
            
            generated_text = response[0]['generated_text']
            
            # CevabÄ± temizle
            if self.model_path.name == "agricultural_gpt2":
                # EÄŸitilmiÅŸ modelden cevabÄ± Ã§Ä±kar
                if "<|cevap|>" in generated_text:
                    answer = generated_text.split("<|cevap|>")[-1]
                    if "<|end|>" in answer:
                        answer = answer.split("<|end|>")[0]
                    answer = answer.strip()
                else:
                    answer = generated_text[len(prompt):].strip()
            else:
                # Base modelden cevabÄ± Ã§Ä±kar
                if "YanÄ±t:" in generated_text:
                    answer = generated_text.split("YanÄ±t:")[-1].strip()
                else:
                    answer = generated_text[len(prompt):].strip()
            
            # Ã‡ok kÄ±sa cevaplarÄ± geniÅŸlet
            if len(answer.split()) < 10:
                answer = self._enhance_short_answer(user_query, answer)
            
            # TarÄ±msal baÄŸlam ekle
            answer = self._add_agricultural_context(user_query, answer)
            
            return answer
            
        except Exception as e:
            console.print(f"âš ï¸ Cevap Ã¼retme hatasÄ±: {e}", style="yellow")
            return self._fallback_response(user_query)
    
    def _enhance_short_answer(self, query: str, answer: str) -> str:
        """KÄ±sa cevaplarÄ± geniÅŸlet"""
        query_lower = query.lower()
        
        # Konu bazlÄ± geniÅŸletmeler
        if 'yanÄ±klÄ±k' in query_lower:
            return f"{answer}\n\nBu hastalÄ±k bakteriyel kÃ¶kenlidir ve hÄ±zla yayÄ±labilir. Erken mÃ¼dahale Ã§ok Ã¶nemlidir. Hasta kÄ±sÄ±mlarÄ± temizlemek ve koruyucu ilaÃ§lama yapmak gerekir."
        elif 'ekim' in query_lower:
            return f"{answer}\n\nEkim baÅŸarÄ±sÄ± iÃ§in toprak hazÄ±rlÄ±ÄŸÄ±, doÄŸru zaman seÃ§imi ve uygun derinlik Ã§ok Ã¶nemlidir. Hava koÅŸullarÄ±nÄ± da takip etmek gerekir."
        elif 'sulama' in query_lower:
            return f"{answer}\n\nSulama zamanÄ± ve miktarÄ± bitkinin geliÅŸim dÃ¶nemine gÃ¶re ayarlanmalÄ±dÄ±r. Toprak tipini ve hava durumunu da gÃ¶z Ã¶nÃ¼nde bulundurmak Ã¶nemlidir."
        
        return f"{answer}\n\nBu konuda daha detaylÄ± bilgi isterseniz, spesifik sorular sorabilirsiniz."
    
    def _add_agricultural_context(self, query: str, answer: str) -> str:
        """TarÄ±msal baÄŸlam ekle"""
        # Ã‡ok genel cevaplarÄ± filtreye
        generic_phrases = [
            "I cannot", "I don't know", "As an AI", "I'm not sure",
            "Sorry", "Unfortunately", "However", "But"
        ]
        
        if any(phrase in answer for phrase in generic_phrases):
            return self._fallback_response(query)
        
        # TarÄ±msal terimler iÃ§eriyorsa olduÄŸu gibi dÃ¶ndÃ¼r
        agricultural_terms = [
            'bitki', 'plant', 'toprak', 'soil', 'gÃ¼bre', 'fertilizer',
            'sulama', 'irrigation', 'hastalÄ±k', 'disease', 'ekim', 'planting'
        ]
        
        if any(term in answer.lower() for term in agricultural_terms):
            return answer
        
        # Genel cevapsa tarÄ±msal versiyona Ã§evir
        return self._fallback_response(query)
    
    def _fallback_response(self, query: str) -> str:
        """Yedek cevap sistemi"""
        query_lower = query.lower()
        
        fallback_responses = {
            'elma': "Elma yetiÅŸtirme konusunda yardÄ±mcÄ± olabilirim. Elma aÄŸaÃ§larÄ± dÃ¼zenli bakÄ±m, uygun budama ve hastalÄ±k kontrolÃ¼ gerektirir.",
            'yanÄ±klÄ±k': "Erken yanÄ±klÄ±ÄŸÄ± ciddi bir bakteriyel hastalÄ±ktÄ±r. Hasta kÄ±sÄ±mlarÄ± hemen kesilmeli ve koruyucu ilaÃ§lama yapÄ±lmalÄ±dÄ±r.",
            'buÄŸday': "BuÄŸday tarÄ±mÄ±nda ekim zamanÄ±, toprak hazÄ±rlÄ±ÄŸÄ± ve gÃ¼breleme Ã§ok Ã¶nemlidir.",
            'domates': "Domates yetiÅŸtirmede sulama, gÃ¼breleme ve hastalÄ±k kontrolÃ¼ baÅŸarÄ±nÄ±n anahtarÄ±dÄ±r.",
            'havuÃ§': "HavuÃ§ iÃ§in derin, gevÅŸek toprak gerekir. DÃ¼zenli sulama ve iyi drenaj Ã¶nemlidir.",
            'sÄ±caklÄ±k': "AÅŸÄ±rÄ± sÄ±caklÄ±kta bitkileri korumak iÃ§in gÃ¶lgeleme, mulch ve dÃ¼zenli sulama gerekir.",
            'sulama': "DoÄŸru sulama zamanÄ± ve tekniÄŸi bitkinin saÄŸlÄ±klÄ± geliÅŸimi iÃ§in kritiktir."
        }
        
        for keyword, response in fallback_responses.items():
            if keyword in query_lower:
                return response
        
        return "Bu konuda size yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸÄ±yorum. Sorunuzu biraz daha spesifik hale getirebilir misiniz? Hangi bitki veya tarÄ±msal konuyla ilgili yardÄ±m istiyorsunuz?"
    
    def chat_loop(self):
        """Ana sohbet dÃ¶ngÃ¼sÃ¼"""
        while True:
            try:
                # KullanÄ±cÄ± giriÅŸi
                user_input = Prompt.ask(
                    f"\nğŸ’¬ [bold green]Siz[/bold green]",
                    default=""
                ).strip()
                
                if not user_input:
                    continue
                
                # Ã–zel komutlar
                if user_input.lower() in ['Ã§Ä±kÄ±ÅŸ', 'exit', 'quit', 'bye']:
                    self._farewell()
                    break
                elif user_input.lower() in ['help', 'yardÄ±m']:
                    self._show_help()
                    continue
                elif user_input.lower() in ['geÃ§miÅŸ', 'history']:
                    self._show_history()
                    continue
                elif user_input.lower() in ['test', 'test et']:
                    self._run_test()
                    continue
                
                # Ana cevap Ã¼retimi
                console.print("\nğŸ§  LLM dÃ¼ÅŸÃ¼nÃ¼yor ve cevap Ã¼retiyor...", style="italic yellow")
                
                response = self.generate_response(user_input)
                
                # KonuÅŸma geÃ§miÅŸine ekle
                self.conversation_history.append({
                    'user': user_input,
                    'bot': response,
                    'timestamp': datetime.now()
                })
                
                # CevabÄ± gÃ¶ster
                console.print(f"\nğŸ§  [bold cyan]TarÄ±m LLM AI[/bold cyan]:\n{response}")
                
            except KeyboardInterrupt:
                self._farewell()
                break
            except Exception as e:
                console.print(f"\nâŒ Bir hata oluÅŸtu: {e}", style="bold red")
                console.print("Tekrar dener misiniz? ğŸ˜Š", style="yellow")
    
    def _run_test(self):
        """Test sorularÄ± Ã§alÄ±ÅŸtÄ±r"""
        console.print("ğŸ§ª Test sorularÄ± Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...", style="cyan")
        
        test_questions = [
            "Elmada erken yanÄ±klÄ±ÄŸÄ± nedir?",
            "BuÄŸday ekim zamanÄ± ne zaman?",
            "Domates sarÄ± yaprak sorunu nasÄ±l Ã§Ã¶zÃ¼lÃ¼r?",
            "AÅŸÄ±rÄ± sÄ±caklÄ±kta bitkileri nasÄ±l koruruz?"
        ]
        
        for i, question in enumerate(test_questions, 1):
            console.print(f"\n[bold blue]Test {i}:[/bold blue] {question}")
            response = self.generate_response(question)
            console.print(f"[bold green]Cevap:[/bold green] {response}")
            console.print("-" * 60)
    
    def _show_help(self):
        """YardÄ±m gÃ¶ster"""
        help_panel = Panel.fit(
            "ğŸ†˜ **GerÃ§ek LLM Chatbot KullanÄ±m KÄ±lavuzu**\n\n"
            "ğŸ’¬ **DoÄŸal KonuÅŸma:**\n"
            "   TarÄ±msal sorularÄ±nÄ±zÄ± normal konuÅŸma dili ile sorun\n\n"
            "ğŸ§  **LLM AvantajlarÄ±:**\n"
            "   â€¢ GerÃ§ek text generation (template deÄŸil)\n"
            "   â€¢ BaÄŸlamsal ve akÄ±cÄ± cevaplar\n"
            "   â€¢ TarÄ±msal konularda Ã¶zel eÄŸitim\n\n"
            "ğŸ¯ **Ã–rnek Sorular:**\n"
            "   â€¢ 'Elmamda yanÄ±klÄ±k var, ne yapmalÄ±yÄ±m?'\n"
            "   â€¢ 'HavuÃ§ ekimi iÃ§in en iyi zaman ne?'\n"
            "   â€¢ 'SÄ±cak havada bitkilerimi nasÄ±l koruyabilirim?'\n\n"
            "âš¡ **Komutlar:**\n"
            "   â€¢ 'test' - Test sorularÄ±nÄ± Ã§alÄ±ÅŸtÄ±r\n"
            "   â€¢ 'geÃ§miÅŸ' - KonuÅŸma geÃ§miÅŸi\n"
            "   â€¢ 'yardÄ±m' - Bu yardÄ±m menÃ¼sÃ¼\n"
            "   â€¢ 'Ã§Ä±kÄ±ÅŸ' - Programdan Ã§Ä±k\n\n"
            "ğŸ’¡ **Ä°pucu:** Bu gerÃ§ek bir AI! Normal konuÅŸma gibi\n"
            "   sorularÄ±nÄ±zÄ± sorun, size detaylÄ± aÃ§Ä±klama yapacak.",
            title="ğŸ†˜ LLM Chatbot YardÄ±m",
            style="cyan"
        )
        console.print(help_panel)
    
    def _show_history(self):
        """Sohbet geÃ§miÅŸini gÃ¶ster"""
        if not self.conversation_history:
            console.print("HenÃ¼z konuÅŸma geÃ§miÅŸi yok! ğŸ˜Š", style="yellow")
            return
        
        console.print(f"\nğŸ“œ Son 5 KonuÅŸma:", style="bold blue")
        
        for i, conv in enumerate(self.conversation_history[-5:], 1):
            time_str = conv['timestamp'].strftime("%H:%M")
            console.print(f"\n{i}. [{time_str}]")
            console.print(f"   [bold blue]Soru:[/bold blue] {conv['user'][:100]}...")
            console.print(f"   [bold green]Cevap:[/bold green] {conv['bot'][:150]}...")
    
    def _farewell(self):
        """VedalaÅŸma"""
        duration = datetime.now() - self.session_start
        duration_min = duration.seconds // 60
        conversation_count = len(self.conversation_history)
        
        farewell_panel = Panel.fit(
            f"ğŸ‘‹ **HoÅŸÃ§akalÄ±n!**\n\n"
            f"ğŸ“Š **LLM Sohbet Ã–zeti:**\n"
            f"â° SÃ¼re: {duration_min} dakika\n"
            f"ğŸ’¬ Mesaj: {conversation_count} adet\n"
            f"ğŸ§  GerÃ§ek LLM ile etkileÅŸim tamamlandÄ±\n\n"
            f"ğŸŒ¾ **Tekrar gÃ¶rÃ¼ÅŸmek Ã¼zere!**\n"
            f"ğŸ¤– LLM'iniz her zaman hizmetinizde!",
            title="ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ãœzere",
            style="bold green"
        )
        console.print(farewell_panel)

def main():
    """Ana fonksiyon"""
    try:
        bot = RealLLMAgriculturalChatbot()
        bot.chat_loop()
    except Exception as e:
        console.print(f"âŒ Program baÅŸlatÄ±lamadÄ±: {e}", style="bold red")

if __name__ == "__main__":
    main() 