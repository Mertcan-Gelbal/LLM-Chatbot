# ğŸš€ Model EÄŸitimi

Bu klasÃ¶r, Botanical BERT modelini eÄŸitmek iÃ§in gerekli dosyalarÄ± iÃ§erir.

## HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# Model eÄŸitimini baÅŸlat
cd CreateModel
python train_model.py
```

## EÄŸitim SÃ¼reci

### 1. Ã–n HazÄ±rlÄ±k
- Dataset'ler `../Data/` klasÃ¶rÃ¼nde olmalÄ±
- GPU/CUDA kurulu olmalÄ± (tercihen)
- Gerekli Python paketleri kurulu olmalÄ±

### 2. Model KonfigÃ¼rasyonu
- **Model:** BERT-base-uncased (kÃ¼Ã§Ã¼k versiyonu)
- **Parametreler:** ~22M (normal BERT'ten %80 kÃ¼Ã§Ã¼k)
- **Kategoriler:** 6 tarÄ±msal sÄ±nÄ±f
- **Max Length:** 128 token

### 3. EÄŸitim Parametreleri
- **Epochs:** 3 (Ã¶zelleÅŸtirilebilir)
- **Batch Size:** 8 (GPU memory'ye gÃ¶re)
- **Learning Rate:** Otomatik (Hugging Face default)
- **Mixed Precision:** FP16 (GPU varsa)

## Ã‡Ä±ktÄ±lar

EÄŸitim sonunda `../Model/` klasÃ¶rÃ¼nde oluÅŸturulacaklar:

```
Model/
â”œâ”€â”€ botanical_bert_model/
â”‚   â”œâ”€â”€ config.json          # Model konfigÃ¼rasyonu
â”‚   â”œâ”€â”€ pytorch_model.bin    # EÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar
â”‚   â”œâ”€â”€ tokenizer.json       # Tokenizer
â”‚   â”œâ”€â”€ vocab.txt           # Vocabulary
â”‚   â””â”€â”€ model_info.json     # Performans bilgileri
â”œâ”€â”€ checkpoints/            # EÄŸitim checkpoints
â””â”€â”€ logs/                   # Training logs
```

## Performance Beklentileri

### Jetson Orin Nano Super (8GB)
- **EÄŸitim SÃ¼resi:** ~10-15 dakika
- **Memory KullanÄ±mÄ±:** ~3-4GB GPU
- **Beklenen Accuracy:** %75-85

### Normal GPU (GTX 1080+)
- **EÄŸitim SÃ¼resi:** ~5-10 dakika  
- **Memory KullanÄ±mÄ±:** ~2-3GB GPU
- **Beklenen Accuracy:** %80-90

## Ã–zelleÅŸtirme

### EÄŸitim Parametrelerini DeÄŸiÅŸtir

```python
# train_model.py iÃ§inde main() fonksiyonunda:

# Daha uzun eÄŸitim
trainer = trainer_obj.train_model(train_df, val_df, epochs=5, batch_size=4)

# Daha bÃ¼yÃ¼k model
trainer_obj.prepare_model("bert-large-uncased")
```

### Batch Size Ayarlama

```python
# GPU memory yetersizse kÃ¼Ã§Ã¼lt
batch_size=4  # veya 2

# GÃ¼Ã§lÃ¼ GPU varsa artÄ±r  
batch_size=16  # veya 32
```

## Hata Ã‡Ã¶zÃ¼mleri

### "CUDA out of memory"
```bash
# Batch size kÃ¼Ã§Ã¼lt
# train_model.py'de batch_size=4 yap
```

### "Dataset bulunamadÄ±"
```bash
# Data klasÃ¶rÃ¼nÃ¼ kontrol et
ls ../Data/
# train.csv, val.csv, test.csv olmalÄ±
```

### "Package bulunamadÄ±"
```bash
# Gerekli paketleri kur
pip install torch transformers sklearn pandas matplotlib seaborn
```

## Model Ä°zleme

```bash
# GPU kullanÄ±mÄ±nÄ± izle
nvidia-smi -l 1

# EÄŸitim loglarÄ±nÄ± izle  
tail -f ../Model/logs/*/events*
```

## Ä°leri Seviye

### Custom Dataset
```python
# Kendi dataset'inizi kullanÄ±n
train_df = pd.read_csv("custom_train.csv")
# Format: text,label
```

### Hiperparametre Tuning
```python
# FarklÄ± learning rate
training_args.learning_rate = 2e-5

# FarklÄ± warmup
training_args.warmup_steps = 200
```

## KullanÄ±m SonrasÄ±

EÄŸitim bittikten sonra:

```bash
# Model'i test et
cd ../Model
python run_model.py

# Ã–rnek tahmin
python -c "
from run_model import predict_text
result = predict_text('Domates yaprak yanÄ±klÄ±ÄŸÄ±')
print(result)
"
``` 